Uses TORGO database for classification.
Uses QCP GIF method for extracting glottal parameters.
Uses openSMILE toolkit for extracting acoustic features.
In this work, SVMs are used as classifiers.
Separate classifiers are trained using reduced and non-reduced feature sets for openSMILE, glottal features and their combination.

GLOTTAL PARAMETER EXTRACTION
The difference in vocal fold vibration between dysarthric and healthy speech production cannot be characterized completely by the rate of vibration (i.e., pitch information).Instead, the mode of vibration of the vocal folds will be affected also. Therefore, the waveform of the acoustic speech excitation generated by the vocal folds, the glottal flow, may have useful discriminating information for dysarthric speech classification. In order to parameterize the glottal source, the flow waveform must be estimated first with GIF using QCP from the speech signal.

QCP
 The QCP method is based on the principles of the closed phase analysis (CP) which estimates the vocal tract response using the covariance method of linear  -  
 prediction from few speech samples located in closed phase of the glottal cycle.
 QCP creates a specific temporal weighting function, called the Attenuated Main Excitation (AME) function, using glottal closure instants (GCIs) estimated from  -  - 
 speech. The AME function is used to attenuate the contribution of the (quasi-) open phase in the computation of theWeighted Linear Prediction (WLP) coefficients,  - 
 which results in good estimates of the vocal tract transfer function.
